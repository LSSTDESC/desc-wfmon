{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e6491bf-776b-4dae-a91c-c0efd2f8da2f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# desc-wfmon/monexp.ipynb: Monitor explorer example\n",
    "\n",
    "We use the classes in desc-wfmon to view monitoring data from DESC gen3 parsl jobs.\n",
    "\n",
    "Typically, this file is copied to the area where the jobs were run.\n",
    "\n",
    "The following sets up to use the local install area, installs desc-wfmon there if needed, and then imports the the system (sysmon) and process (wfmon) monitor explorers. To force a rebuild of desc-wfmon, remove ./install."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4659582-8f7d-40fc-bef1-916456271164",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Notebook version is 7.15')\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "homedir = os.getenv('HOME')\n",
    "print(f\"Current directory is {os.getcwd()}\")\n",
    "stzone = datetime.datetime.utcnow().astimezone().tzinfo\n",
    "print(f\"Local time zone is {stzone}\")\n",
    "srcdir = f\"{homedir}/desc/dev\"\n",
    "nbdir = srcdir + '/desc-wfmon/ipynb'\n",
    "%run $nbdir/setup.ipynb\n",
    "print('Checking for local install of desc-wfmon')\n",
    "%run install/setup.py\n",
    "\n",
    "print(f\"Python version is {sys.version}\")\n",
    "print(f\"Python search path starts with {sys.path[0]}:{sys.path[1]}:{sys.path[2]}\")\n",
    "!pwd\n",
    "import pandas\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as pltcol\n",
    "import desc.wfmon\n",
    "import desc.sysmon\n",
    "for pkg in [desc.wfmon, desc.sysmon]:\n",
    "    print(f\"{pkg} version is {pkg.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313a69d9-92c0-4f9b-9633-a30e27ba851b",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "Define some useful constants and specify the location of the monitoring data files. Set dir to point to your area.\n",
    "\n",
    "In monexp.py, define object monexp with attributes that override any of those in monexp_def below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c11c974-6953-4089-b61f-58fd3992a97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the config.\n",
    "%run monexp.py\n",
    "\n",
    "# Defaults for configuration.\n",
    "class monexp_def:\n",
    "    dir = os.getcwd()\n",
    "    name = os.path.basename(os.getcwd())\n",
    "    run_id = None\n",
    "    stunit = 'minute'           # Unit for time axes\n",
    "    sbunit = 'gb'               # Unit for memory, I/O\n",
    "    tmin = 0                    # Min time for time axes\n",
    "    tmax = 20                   # Max time for time axes\n",
    "    taskrunmax = 1.02           # Max for running task axes\n",
    "    taskrunmax_percpu = True    # If true, taskrunmax is scaled bu ncpu\n",
    "    taskrunmax_pernode = True   # If true taskrunmax is scaled by nnod\n",
    "    tasktimemax = 200           # Max for time/task axis [s]\n",
    "    taskcount_interval = 10     # Sampling interval for evaluating try task counts\n",
    "    tzoff = 0                   # Time zone offset between system and process monitors\n",
    "    tlatencymax = 20            # Max for latency axis\n",
    "    tlatrunmax = 100            # Max for lataency + run time\n",
    "    iosummax = 1000             # Max for the integrated I/O plot [GB]\n",
    "    task_id_plot = None         # Task index or type for latency plots (e.g. 0 or 'isr')\n",
    "    t0_source = \"config\"        # 'congig' for config.json, 'system' for sysmon, 'run' for run start of first task\n",
    "    \n",
    "# Set defaults for any missing parameters.\n",
    "if 'monexp' not in dir():\n",
    "    monexp = monexp_def\n",
    "else:\n",
    "    for nam in monexp_def.__dict__:\n",
    "        if nam[0:2] == '__': continue\n",
    "        if not hasattr(monexp, nam):\n",
    "            setattr(monexp, nam, getattr(monexp_def, nam))\n",
    "        \n",
    "# Time conversions and plotting units.\n",
    "tunits = {'second':1, 'minute':60, 'hour':3600, 'day':24*3600}\n",
    "stunit = monexp.stunit\n",
    "tunit = tunits[stunit]\n",
    "\n",
    "# Memory and I/O conversion plotting units.\n",
    "bunits = {'mb':2**20, 'gb':2**30}\n",
    "gb = bunits['gb']\n",
    "sbunit = monexp.sbunit\n",
    "bunit = bunits[sbunit]\n",
    "bunit_sys = bunit/gb\n",
    "\n",
    "# Time range for the plots\n",
    "# if tmax <= tmin, it will be reset with the data below\n",
    "tmin = monexp.tmin\n",
    "tmax = monexp.tmax\n",
    "\n",
    "print(f\"Time zone offset: {monexp.tzoff} sec\")\n",
    "\n",
    "# Plot size\n",
    "pdx = 20\n",
    "pdy = 6\n",
    "\n",
    "line = '-----------------------------------------------------------'\n",
    "fread = monexp.dir + '/README.txt'\n",
    "if os.path.exists(fread):\n",
    "    fin = open(fread, 'r')\n",
    "    #readme = fin.read().strip()\n",
    "    readme = fin.readlines()\n",
    "    with open(fread) as fin:\n",
    "        readme = [line.rstrip() for line in fin]\n",
    "else:\n",
    "    raise Exception('README.txt not found')\n",
    "print('README:')\n",
    "for line in readme: print(line)\n",
    "pttl = monexp.name + \": \" + readme[0]\n",
    "print(f\"Plot title: {pttl}\")\n",
    "pfx = monexp.name\n",
    "print(f\"Plot file prefix: {pfx}\")\n",
    "sfx = '.png'\n",
    "print(f\"Plot file suffix: {sfx}\")\n",
    "plt.rc('font', size=16)\n",
    "plt.rc('savefig', facecolor='white', bbox='tight')\n",
    "plt.rc('axes', titlesize='medium')\n",
    "\n",
    "pandas.options.display.width = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b76a712-9b67-4001-8aaa-7595cce6f437",
   "metadata": {},
   "source": [
    "## Fetch system-level monitoring data\n",
    "\n",
    "System level monitoring data is collected using *desc.sysmon*. The data is in csv format and is read here with *pandas*.\n",
    "\n",
    "The column names follow from those of the corresponding *psutil* variables.\n",
    "\n",
    "We fetch the number of CPUs and total memory and check both are consistent for all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de22c85c-60c5-4b40-8b2c-ac9ce404e7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "havesym = False\n",
    "ncpu = 1\n",
    "try:\n",
    "  sym = pandas.read_csv(monexp.dir + '/sysmon.csv')\n",
    "  havesym = True\n",
    "  print(f\"System monitor sample count: {len(sym)}\")\n",
    "  print(f\"System monitor columns:\")\n",
    "  for cnam in sym.columns:\n",
    "    print(f\"  {cnam}\")\n",
    "  \n",
    "  assert(len(sym.cpu_count.unique()) == 1)\n",
    "  ncpu = sym.cpu_count[0]\n",
    "  print(f\"CPU count is {ncpu:.0f}\")\n",
    "\n",
    "  assert(len(sym.mem_total.unique()) == 1)\n",
    "  maxmem = sym.mem_total[0]/bunit_sys\n",
    "  print(f\"Total memory is {maxmem:.1f} {sbunit}\")\n",
    "except:\n",
    "  print(f\"WARNING: System monitoring data not found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45ba343-2473-4d4c-834b-2b735020201c",
   "metadata": {},
   "source": [
    "## Fetch task output data\n",
    "If the file task-output-size.log is present that it is assume to be table containing (time size free) where size is the amount of\n",
    "task data witten and free is the space remaining on the disk, both in GiB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d6f189-8726-4e4a-a142-39c0e7380557",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "toname = 'task-output-size.log'\n",
    "if os.path.isfile(toname):\n",
    "    try:\n",
    "        df_taskout = pandas.read_csv(toname, sep=' ', skipinitialspace=True, names=['time', 'size', 'free'])\n",
    "        have_taskout = len(df_taskout)\n",
    "        print(df_taskout)\n",
    "    except Exception as e:\n",
    "        print(f\"Unable to parse {toname}: {e}\")\n",
    "        have_taskout = False\n",
    "if have_taskout:\n",
    "    df_taskout['dsize'] = df_taskout['size'].shift(0) - df_taskout['size'].shift(1)\n",
    "    df_taskout['dtime'] = df_taskout['time'].shift(0) - df_taskout['time'].shift(1)\n",
    "    df_taskout['rate'] = df_taskout.dsize/df_taskout.dtime\n",
    "    print(df_taskout)\n",
    "    taskout_minsize = df_taskout['size'].min()\n",
    "    taskout_maxsize = df_taskout['size'].max()\n",
    "    taskout_minfree = df_taskout['free'].min()\n",
    "    sfto = '12.3f'\n",
    "    print(f\"Task output has {len(df_taskout)} entries.\")\n",
    "    print(f\" Starting task size: {df_taskout.iloc[0]['size']:{sfto}} GiB\")\n",
    "    print(f\"    Final task size: {df_taskout.iloc[-1]['size']:{sfto}} GiB\")\n",
    "    print(f\"  Minimum task size: {taskout_minsize:{sfto}} GiB\")\n",
    "    print(f\"  Maximum task size: {taskout_maxsize:{sfto}} GiB\")\n",
    "    print(f\" Mininum free space: {taskout_minfree:{sfto}} GiB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdba9f2-8335-4c52-8918-dc4a352d9a48",
   "metadata": {},
   "source": [
    "## Fetch the process-level monitoring data\n",
    "\n",
    "The process monitoring data is read from the mysql DB produced by parsl. Of particular interest is the task table where metrics are sampled at regular intervals seprately for each job.\n",
    "\n",
    "We \"fix\" that data to make it more amenable for analysis. Among many other modifications, fixing converts time strings to integers and add a procsum (process summary) table which sums the contributions from all jobs. Although the sampling interval is the same for all jobs, they have different offsets and so there is some ambiguity in this summing.\n",
    "\n",
    "For disk and network I/O, integrated values are recorded but the differential values (the amount read or written each sampling interval) are of interest here. A separate call is made to build a procsum table that includes these differential values. This is not done automatically because it can be slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e145d796-d1a6-47ee-aee9-a839192abae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbg = 1\n",
    "showraw = False\n",
    "for subdir in ['', '/runinfo']:\n",
    "    fnam = f\"{monexp.dir}{subdir}/monitoring.db\"\n",
    "    if os.path.exists(fnam):\n",
    "        if showraw:\n",
    "            dbr = desc.wfmon.MonDbReader(fnam, fix=False, dodelta=False, dbg=dbg)\n",
    "            print('----------- Workflow ------------------')\n",
    "            print(dbr['workflow'])\n",
    "            print('---------------------------------------')\n",
    "        else:\n",
    "            dbr = desc.wfmon.MonDbReader(fnam, dodelta=True, dbg=dbg, run_id=monexp.run_id)\n",
    "print(f\"Label: {pttl}\")\n",
    "dbr.tables(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d263b4a-dad7-491f-99cf-b087d46b2f8d",
   "metadata": {},
   "source": [
    "## Run selection\n",
    "Define handles for the process tables of interest:\n",
    "\n",
    "* wkf - Workflow table with one entry for each run\n",
    "* tsk - Task table holds a description of each task\n",
    "* tst - Try table has entry each time a task is run or rerun\n",
    "* prc - Process table holds sampled data for each process\n",
    "* psm - Procsum (process summary) table holds samples summed over all processes\n",
    "\n",
    "If the process monitor includes more than one run, then select one run to study here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f993f184-6981-419a-b131-1eff8749de5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrun = len(dbr.table('workflow'))\n",
    "if nrun == 1:\n",
    "    print('One run found.')\n",
    "    wkf = dbr.table('workflow')\n",
    "    tsk = dbr.table('task')\n",
    "    tst = dbr.table('try')\n",
    "    prc = dbr.table('resource')\n",
    "    psm = dbr.table('procsum')\n",
    "else:\n",
    "    rqry = 'run_idx==0'\n",
    "    print(f\"Selecting runs with {rqry}\")\n",
    "    wkf = dbr.table('workflow').query(rqry)\n",
    "    tsk = dbr.table('task').query(rqry)\n",
    "    tst = dbr.table('try').query(rqry)\n",
    "    prc = dbr.table('resource').query(rqry)\n",
    "    psm = dbr.table('procsum').query(rqry)\n",
    "print(f\"Process table entry count: {len(prc)}\")\n",
    "print(f\"Procsum table entry count: {len(psm)}\")\n",
    "if havesym:\n",
    "    print(f\" System table entry count: {len(sym)}\")\n",
    "else:\n",
    "    print(f\"System table was not found.\")\n",
    "have_procsum = len(psm) > 0\n",
    "\n",
    "print(f\"Run nodes: {tst.hostname.dropna().unique()}\")\n",
    "print(f\"Workflow count: {len(dbr['workflow'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bdb1f9-2130-4854-b316-614d39109edc",
   "metadata": {},
   "source": [
    "## Task counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b27d03a-7d62-4341-acca-79cfd7433ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntsk = len(tsk)\n",
    "ntry = len(tst)\n",
    "ntsk_good = wkf.at[0, 'tasks_completed_count']\n",
    "ntsk_fail = wkf.at[0, 'tasks_failed_count']\n",
    "fmt = f\"{len(str(ntsk))}d\"\n",
    "print(f\"   Task failed count: {ntsk_fail:{fmt}}/{ntsk}\")\n",
    "print(f\"Task succeeded count: {ntsk_good:{fmt}}/{ntsk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854b48ad-4556-42f2-8f4b-a8908f8b7af3",
   "metadata": {},
   "source": [
    "## Run nodes\n",
    "Fetch the list of processing nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f742ad29-8d4f-4556-8db2-ed1cb229872a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = tst.hostname.dropna().unique()\n",
    "nnod = len(nodes)\n",
    "if nnod == 1:\n",
    "    print(f\"The run used one node: {nodes[0]}\")\n",
    "else:\n",
    "    print(f\"The run used {nnod} nodes: {nodes}\")\n",
    "taskrunmax = monexp.taskrunmax\n",
    "if monexp.taskrunmax_percpu:\n",
    "    taskrunmax = taskrunmax * ncpu\n",
    "if monexp.taskrunmax_pernode:\n",
    "    taskrunmax = taskrunmax * nnod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5d916e-f8e0-428e-8865-a47c5c46dea3",
   "metadata": {},
   "source": [
    "## Time range\n",
    "\n",
    "For convenience we add a column tfix to each table that converts to units defined above. The try table includes three state timees:\n",
    "* launched - The task is made ready to run\n",
    "* running - The CPU process starts. (Not present when process monitoring is disabled.)\n",
    "* returned - The CPU process terminates.  \n",
    "\n",
    "The zero for time is the first entry in the system monitor if present. Otherwise the value from process monitor is used. The difference between these (in the selected time units) is recorded in dtfix\n",
    "The time offset used in the process tables is applied to the system table. A configureable offset is also added, e.g. to account for time zone issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a13be63-ebbc-477a-a1ed-92ae01ee1aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "delt = dbr.monitoring_interval\n",
    "if delt is None : delt = 0.0\n",
    "deltfix = delt/tunit\n",
    "dtfix = 0.0\n",
    "nttry = len(tst)\n",
    "ntlau = tst.task_try_time_launched.notna().sum()\n",
    "ntrun = tst.task_try_time_running.notna().sum()\n",
    "ntret = tst.task_try_time_returned.notna().sum()\n",
    "print(f\"Task returned/run/launched/try count: {ntret}/{ntrun}/{ntlau}/{nttry}\")\n",
    "# t0sec is our zero of time in the parsl monitor time zone\n",
    "if monexp.t0_source == 'system':\n",
    "    # System monitor started.\n",
    "    t0sec_sym = sym.time[0]\n",
    "    t0sec_dbr = t0sec_sym - monexp.tzoff\n",
    "elif monexp.t0_source == 'run':\n",
    "    # First job started running.\n",
    "    t0sec_dbr = tst.task_try_time_running.min() + dbr.t0\n",
    "    t0sec_sym = t0sec_dbr + monexp.tzoff\n",
    "elif monexp.t0_source == 'config':\n",
    "    # Shortly after apprun_g3wfpipe started running.\n",
    "    t0sec_sym = os.path.getmtime('config.json')\n",
    "    t0sec_dbr = t0sec_sym - monexp.tzoff\n",
    "else:\n",
    "    raise Exception(f\"Invalid t0_source: {monexp.t0_source}\")\n",
    "dtfix = (t0sec_dbr - dbr.t0)/tunit\n",
    "if havesym:\n",
    "    deltsys = (max(sym.time) - min(sym.time))/float(len(sym) - 1)\n",
    "wkf['tfix_began']     = wkf.time_began/tunit - dtfix\n",
    "wkf['tfix_completed'] = wkf.time_completed/tunit - dtfix\n",
    "newlatency = True\n",
    "if newlatency:\n",
    "    tst['trun'] = tst.status_rundone - tst.status_running  # process run time\n",
    "    tst['tpst'] = tst.status_alldone - tst.status_rundone  # post-processing time\n",
    "else:\n",
    "    tst['trun'] = tst.task_try_time_returned - tst.task_try_time_running\n",
    "tst['tfix_launched']  = tst.task_try_time_launched/tunit - dtfix\n",
    "tst['tfix_running']   = tst.task_try_time_running/tunit - dtfix\n",
    "tst['tfix_returned']  = tst.task_try_time_returned/tunit - dtfix\n",
    "tsk['tfix_invoked']   = tsk.task_time_invoked/tunit - dtfix\n",
    "prc['tfix']           = prc.timestamp/tunit - dtfix\n",
    "if have_procsum:\n",
    "    psm['tfix'] = psm.timestamp/tunit - dtfix\n",
    "    psm_tfix = psm['tfix']\n",
    "    psm_interval_tfix = pandas.concat([pandas.Series([(psm_tfix[0]-deltfix)]), psm_tfix])\n",
    "if havesym:\n",
    "    sym['tfix'] = (sym.time - t0sec_sym)/tunit\n",
    "if have_taskout:\n",
    "    df_taskout['tfix'] = (df_taskout.time - t0sec_sym)/tunit\n",
    "\n",
    "twkf1 = wkf.tfix_began.min()\n",
    "twkf2 = wkf.tfix_completed.max()\n",
    "tlau1 = tst.tfix_launched.min()\n",
    "tlau2 = tst.tfix_launched.max()\n",
    "tinv1 = tsk.tfix_invoked.min()\n",
    "tinv2 = tsk.tfix_invoked.max()\n",
    "tprc1 = prc.tfix.min()\n",
    "tprc2 = prc.tfix.max()\n",
    "if have_procsum:\n",
    "    tpsm1 = psm.tfix.min()\n",
    "    tpsm2 = psm.tfix.max()\n",
    "if havesym:\n",
    "    tsym1 = sym.tfix.min()\n",
    "    tsym2 = sym.tfix.max()\n",
    "if have_taskout:\n",
    "    ttko1 = df_taskout.tfix.min()\n",
    "    ttko2 = df_taskout.tfix.max()\n",
    "if tmax <= tmin:\n",
    "    tmax = 1.01*tprc2\n",
    "\n",
    "print(f\"T0 source: {monexp.t0_source}\")\n",
    "print(f\"System/process TZ offset: {monexp.tzoff} sec\")\n",
    "print(f\"  Proc time interval: {delt:.2f} sec\")\n",
    "if havesym:\n",
    "    print(f\"   Sys time interval: {deltsys:.2f} sec\")\n",
    "print(f\" Workflow time range: ({twkf1:.2f}, {twkf2:.2f}) {stunit}\")\n",
    "print(f\"   Invoke time range: ({tinv1:.2f}, {tinv2:.2f}) {stunit}\")\n",
    "print(f\"   Launch time range: ({tlau1:.2f}, {tlau2:.2f}) {stunit}\")\n",
    "print(f\"  Process time range: ({tprc1:.2f}, {tprc2:.2f}) {stunit}\")\n",
    "if have_procsum:\n",
    "    print(f\"  Procsum time range: ({tpsm1:.2f}, {tpsm2:.2f}) {stunit}\")\n",
    "if havesym:\n",
    "    print(f\"   System time range: ({tsym1:.2f}, {tsym2:.2f}) {stunit}\")\n",
    "if have_taskout:\n",
    "    print(f\"  Task output time range: ({ttko1:.2f}, {ttko2:.2f} {stunit}\")\n",
    "print(f\" Plotting time range: ({ tmin:.2f}, { tmax:.2f}) {stunit}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59efc9a-7612-4e03-b5e7-5b9db2f8d6ee",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "We look at the task types, how many of each were run and plot the distribution of run times for the tasks.\n",
    "\n",
    "If process monitoring was disabled then the run start times are not recorded in the try table and the run time plots are empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8fb4a2-e198-48d4-80e0-6cce3bb642d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntid = len(tsk.task_idx.unique())\n",
    "ntry = len(tst)\n",
    "trunMax = (tst.task_try_time_running - tst.task_try_time_launched).dropna().max()\n",
    "tstDone = tst.query(\"task_try_time_returned==task_try_time_returned\")\n",
    "ntryDone = len(tstDone)\n",
    "ntskByTid = []\n",
    "for itid in range(ntid):\n",
    "    ntskByTid.append(len(tsk.query(f\"task_idx=={itid}\")))\n",
    "ntskByTidMax = max(ntskByTid)\n",
    "print(f\"         Task idx count: {ntid}\")\n",
    "print(f\"             Task count: {ntsk}\")\n",
    "print(f\"      Unique task count: {len(tsk.task_id.unique())}\")\n",
    "print(f\"              Try count: {ntry}\")\n",
    "print(f\"         Try done count: {ntryDone}\")\n",
    "print(f\"  Max task by tid count: {ntskByTidMax}\")\n",
    "\n",
    "print()\n",
    "print(\"Task name [done/count]\")\n",
    "assert(ntid == len(dbr.task_names))\n",
    "tstDoneByTask = [None]*ntid\n",
    "tstRunTimeByTask = [None]*ntid\n",
    "for itid in range(ntid):\n",
    "    tstDoneByTask[itid] = tstDone.query(f\"task_idx=={itid}\")\n",
    "    if newlatency:\n",
    "        t1 = tstDoneByTask[itid].status_running\n",
    "        t2 = tstDoneByTask[itid].status_rundone\n",
    "    else:\n",
    "        t1 = tstDoneByTask[itid].task_try_time_running\n",
    "        t2 = tstDoneByTask[itid].task_try_time_returned\n",
    "    tstRunTimeByTask[itid] = (t2 - t1).dropna()\n",
    "    td = tstRunTimeByTask[itid]\n",
    "    ndif = len(td)\n",
    "    nrun = t1.count()\n",
    "    ndone = t2.count()      # count ignores NaN\n",
    "    if ndone == 0:\n",
    "        savg = \"\"\n",
    "    elif nrun == 0:\n",
    "        savg = \"\" if ntrun == 0 else f\"Run start times not found\"\n",
    "    elif ndif != ndone:\n",
    "        savg = f\"ERROR: Inconsistent run start and returned entries\"\n",
    "    elif len(td):\n",
    "        avg = td.mean()\n",
    "        savg = f\" {avg:.1f}\"\n",
    "    else:\n",
    "        savg = ''\n",
    "    print(f\"{itid:4}: {dbr.task_names[itid]} [{ndone}/{nrun}/{dbr.task_name_counts[itid]}]{savg}\")\n",
    "\n",
    "\n",
    "x1 = 0\n",
    "x2 = monexp.tasktimemax\n",
    "# Fetch run times for each type of task\n",
    "taskdts = [None]*ntid\n",
    "cols = [None]*max(ntid,3)\n",
    "ncol = len(cols)\n",
    "labs = [None]*ntid\n",
    "#mycols = ['red', 'green', 'orange', 'blue', 'yellow', 'violet', 'cyan', 'pink']\n",
    "for itid in range(ntid):\n",
    "    td = tstRunTimeByTask[itid]\n",
    "    if len(td):\n",
    "        avg = td.mean()\n",
    "        savg = f\" {avg:.1f}\"\n",
    "    else:\n",
    "        savg = ''\n",
    "    taskdts[itid] = td.clip(upper=0.999*x2)\n",
    "    labs[itid] = f\"{dbr.task_names[itid][0:20]} [{len(tstDoneByTask[itid])}/{dbr.task_name_counts[itid]}]{savg} sec\"\n",
    "plt.figure(figsize=(pdx, pdy))\n",
    "plt.hist(bins=100, range=(x1, x2), x=taskdts, stacked=True, label=labs)\n",
    "plt.legend(loc=\"upper right\", fontsize=16)\n",
    "if newlatency:\n",
    "    plt.xlabel('Process run time [sec]')\n",
    "else:\n",
    "    plt.xlabel('Time: returned - running [sec]')\n",
    "plt.ylabel('Number of tasks')\n",
    "junk = plt.xlim([x1, x2])\n",
    "plt.title(pttl)\n",
    "plt.savefig(pfx+'ttask'+sfx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4b64b1-2829-467b-8762-35d56cc8816d",
   "metadata": {},
   "source": [
    "## Throughput per task type\n",
    "\n",
    "The *taskcounts* method uses the task state times from the try table to evaluate the integrated number of tasks that have reached each of the task states\n",
    "(launched, running, returned) as a function of time.\n",
    "\n",
    "If there is more than one task type, we plot this for the running and returned states with a separate curve for each type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cc6400-bde1-4070-9483-8399ce086a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tprc2 > 0.8*tmax:\n",
    "    legloc = \"upper left\"\n",
    "else:\n",
    "    legloc = \"upper right\"\n",
    "print(f\"Task count interval: {monexp.taskcount_interval}\")\n",
    "dbr.taskcounts(delt=monexp.taskcount_interval)\n",
    "for dfs in dbr._taskcounts:\n",
    "    for idf in dfs:\n",
    "        dfs[idf]['tfix'] = dfs[idf].time/tunit - dtfix\n",
    "#dbr._taskcounts[0]['running']\n",
    "#print(dbr.taskcounts('returned', 0))\n",
    "state = 'running'\n",
    "tsclau = dbr.taskcounts('launched')\n",
    "tscrun = dbr.taskcounts('running')\n",
    "tscret = dbr.taskcounts('returned')\n",
    "tscact = tscrun - tscret   # Number of task running\n",
    "# Evaluate the times at which all tasks are launched, started and running.\n",
    "tfix_procs_launched = tsclau.at[tsclau.idxmax()['all'], 'tfix']\n",
    "tfix_procs_running  = tscrun.at[tscrun.idxmax()['all'], 'tfix']\n",
    "tfix_procs_done     = tscret.at[tscret.idxmax()['all'], 'tfix']\n",
    "print(f\"Last task return time: {tfix_procs_done:0.2f} {stunit}\")\n",
    "if ntid > 1:\n",
    "    for sstat in ['running', 'returned']:\n",
    "        plt.figure(figsize=(pdx, pdy))\n",
    "        tsc = dbr.taskcounts(sstat)\n",
    "        for itid in range(ntid):\n",
    "            plt.plot(tsc.tfix, tsc[itid], '.', color=cols[itid%ncol], label=labs[itid])\n",
    "        plt.xlabel(f\"Time [{stunit}]\")\n",
    "        plt.ylabel(f\"Integrated {sstat} task count\")\n",
    "        plt.legend(loc=legloc, fontsize=16)\n",
    "        plt.grid(True)\n",
    "        junk = plt.axis([tmin, tmax, 0, 1.02*ntskByTidMax])\n",
    "        plt.title(pttl)\n",
    "        plt.savefig(f\"{pfx}sn{sstat[0:3]}{sfx}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d851cd-5fd5-4e49-9a00-133afbb45ec1",
   "metadata": {},
   "source": [
    "## Launch rate\n",
    "Estimate launch rate using the first sample with launched tasks and the last before the maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fc11bf-5d05-4b21-a7c9-3174a907c741",
   "metadata": {},
   "outputs": [],
   "source": [
    "isam1 = None\n",
    "for isam in range(len(tsclau)):\n",
    "    ntaskl = tsclau['all'][isam]\n",
    "    if isam1 is None and ntaskl > 0: isam1 = isam\n",
    "    if ntaskl >= ntsk: break\n",
    "isam2 = isam - 1\n",
    "if isam1 is not None and isam2 > isam1:\n",
    "    tsaml1 = tsclau.tfix[isam1]\n",
    "    tsaml2 = tsclau.tfix[isam2]\n",
    "    ntskl1 = tsclau['all'][isam1]\n",
    "    ntskl2 = tsclau['all'][isam2]\n",
    "    dtsaml = tsaml2 - tsaml1\n",
    "    dntskl = ntskl2 - ntskl1\n",
    "    launch_rate = dntskl/dtsaml/tunit\n",
    "    launch_time = 1./launch_rate\n",
    "    print(f\"Launch samples: [{isam1}..{isam2}]\")\n",
    "    print(f\"Launch rate is {launch_rate:.1f} Hz  ({ntskl2:.1f} - {ntskl1:.1f} = {dntskl:.0f} tasks in {dtsaml:.3f} {stunit})\")\n",
    "    print(f\"Launch time is {1000.0/launch_rate:.1f} msec\")\n",
    "else:\n",
    "    print('Unable to evaluate launch rate.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce49a1b-e526-40a9-be9f-91f153e6baa0",
   "metadata": {},
   "source": [
    "## Throughput\n",
    "\n",
    "This figure shows the total number of jobs launched, started and finished as function of time.\n",
    "The time at which the last task completes is the time for the run (workflow) and is shown on the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae06741-2a24-4667-ab64-76bcf42029ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(pdx, pdy))\n",
    "plt.plot(tsclau.tfix, tsclau['all'], '.', color=cols[0], label=f\"Launched [{tsclau['all'].max():.0f}] {tfix_procs_launched:.1f} {stunit}\")\n",
    "plt.plot(tscrun.tfix, tscrun['all'], '.', color=cols[1], label=f\"Running [{tscrun['all'].max():.0f}] {tfix_procs_running:.1f} {stunit}\")\n",
    "plt.plot(tscret.tfix, tscret['all'], '.', color=cols[2], label=f\"Returned [{tscret['all'].max():.0f}] {tfix_procs_done:.1f} {stunit}\")\n",
    "plt.xlabel(f\"Time [{stunit}] (T0 from {monexp.t0_source})\")\n",
    "plt.ylabel('Integrated task count')\n",
    "plt.legend(loc=legloc, fontsize=16)\n",
    "plt.grid(True)\n",
    "ymin = 0\n",
    "ymax = 1.02*ntsk\n",
    "junk = plt.axis([tmin, tmax, ymin, ymax])\n",
    "if ntryDone == ntry and tfix_procs_done <= tmax:\n",
    "    tlab = tfix_procs_done\n",
    "    wx = tmax - tmin\n",
    "    wy = ymax - ymin\n",
    "    if tlab > 0.8*tmax:\n",
    "        ha = 'right'\n",
    "        dx = -0.005*wx\n",
    "    else:\n",
    "        ha = 'left'\n",
    "        dx = 0.005*wx\n",
    "    plt.plot([tlab, tlab], [ymin, ymax], color='gray', linestyle='-')\n",
    "    plt.text(tlab + dx, ymin + 0.015*wy, f\"{tlab:.1f} {stunit}\", ha=ha)\n",
    "plt.title(pttl)\n",
    "plt.savefig(pfx+'throughput'+sfx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75a76a9-977f-4290-85ae-f9ecd1e947b0",
   "metadata": {},
   "source": [
    "## Running task count\n",
    "\n",
    "The difference between the integrated running and returned task counts provides the number of active tasks as a function of time.\n",
    "Separates curves are plotted here for each task type and for all combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b036148a-6b51-437c-8cc9-baf342682e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin = tmin\n",
    "xmax = tmax\n",
    "ymin = 0\n",
    "ymax = taskrunmax\n",
    "plt.figure(figsize=(pdx, pdy))\n",
    "tscact = (tscrun['all'] - tscret['all'])\n",
    "if ntid > 1: plt.step(x=tscrun.tfix, y=tscact, color='black', label='all')\n",
    "for itid in range(ntid):\n",
    "    ytmp = tscrun[itid] - tscret[itid]\n",
    "    plt.step(x=tscret.tfix, y=ytmp, color=cols[itid%ncol], label=labs[itid])\n",
    "plt.xlabel(f\"Time [{stunit}]\")\n",
    "plt.ylabel('Running task count')\n",
    "plt.legend(fontsize=16)\n",
    "plt.title(pttl)\n",
    "plt.grid(True)\n",
    "junk = plt.axis([xmin, xmax, ymin, ymax])\n",
    "plt.title(pttl)\n",
    "plt.savefig(pfx+'nruntask'+sfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a292d5-2105-4028-9901-78686b9a64e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d354ea7d-e069-43a9-bd0f-8581dc2b6284",
   "metadata": {},
   "source": [
    "## Procsum estimate of running task count\n",
    "\n",
    "The preceding estimate of running task count is based on the recorded process start and stop times and so can be evaluated precisely at a very fine time granularity.\n",
    "The running task count can also be estimated from the procsum table but the time resolution is limited by the resource sampling frequency.\n",
    "The two are overlaid in the following plot.\n",
    "This is an important check because the following procsum estimates of utilization and I/O (which cannot be obtained otherwise) have the same limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2e5f42-7054-414c-acef-d5152f070b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if have_procsum:\n",
    "    xmin = tmin\n",
    "    xmax = tmax\n",
    "    #xmin = 4\n",
    "    #xmax = 8\n",
    "    ymin = 0\n",
    "    ymax = taskrunmax\n",
    "    plt.figure(figsize=(pdx, pdy))\n",
    "    psmproc = psm.procsum_time_clock/delt\n",
    "    #plt.step(x=tscrun.tfix, y=tscact, color='black', label='all')\n",
    "    plt.step(x=psm_tfix, y=psmproc, where='pre', color='cyan', label=f\"Procsum processes [{len(psmproc)}] {psmproc.median():.1f}\")\n",
    "    plt.plot(tscrun.tfix, tscact, '.', color='orchid', label=f\"Task processes [{len(tscact)}] {tscact.median():.1f}\")\n",
    "    plt.xlabel(f\"Time [{stunit}]\")\n",
    "    plt.ylabel('CPU count')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    junk = plt.axis([xmin, xmax, ymin, ymax])\n",
    "    plt.title(pttl)\n",
    "    plt.savefig(pfx+'proccount'+sfx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483fe358-2b2c-419d-a9e0-57c07b6f3eec",
   "metadata": {},
   "source": [
    "## CPU utilization\n",
    "\n",
    "The CPU utilization is the fraction of time each \"CPU\" is working, i.e. not in the idle state. The system monitor gets this direcly from *psutil.cpy_percent* which return a value averaged over time since the last sampling and averaged over all hyperthreads.\n",
    "We obtain an estimate for running task processes by summing the times each process spends in the user and system states and the dviding by the sampling time and total number of available hyperthreads.\n",
    "\n",
    "The following plot shows these two values as a function of time.\n",
    "We expect the system values to be larger because they include CPU used by the workflow and monitoring systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b976697-24cf-4c65-b157-6557c1d0892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin = tmin\n",
    "xmax = tmax\n",
    "ymin = 0\n",
    "ymax = 102\n",
    "plt.figure(figsize=(pdx, pdy))\n",
    "if havesym:\n",
    "    cpp = sym.cpu_percent\n",
    "    plt.step(x=sym.tfix, y=cpp, where='pre', color='orange', label=f\"System [{len(cpp)}] {cpp.median():.1f}%\")\n",
    "# To get a process estimate, we divide the total user+sys time by the time interval and number of CPU.\n",
    "if have_procsum:\n",
    "    peff = 100*(psm.procsum_time_user+psm.procsum_time_system)/delt/ncpu\n",
    "    plt.step(x=psm.tfix, y=peff, color='blue', label=f\"Process [{len(peff)}] {peff.median():.1f}%\")\n",
    "plt.xlabel(f\"Time [{stunit}]\")\n",
    "plt.ylabel('CPU utilization [%]')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "junk = plt.axis([xmin, xmax, ymin, ymax])\n",
    "plt.title(pttl)\n",
    "plt.savefig(pfx+'cpueff'+sfx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601904ef-8338-4109-94a4-eb40571ca481",
   "metadata": {},
   "source": [
    "## Task count and utilization\n",
    "Here we overlay the running task count with the total task utilization now normalized to the number of CPUs (hyperthreads).\n",
    "For perlmutter, that number is 256."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82af6e7-3a19-431c-980d-60aa5c91ae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin = tmin\n",
    "xmax = tmax\n",
    "ymin = 0\n",
    "ymax = taskrunmax\n",
    "show_sysutil = False\n",
    "show_psmprocs = False\n",
    "plt.figure(figsize=(pdx, pdy))\n",
    "# System utilization\n",
    "if show_sysutil:\n",
    "    scpu = sym.cpu_percent*ncpu*0.01\n",
    "    plt.step(x=sym.tfix, y=scpu, where='pre', color='orange', linestyle='-', label=f\"System utilization [{len(scpu)}] {scpu.median():0.1f}\")\n",
    "# Procsum process count.\n",
    "if have_procsum and show_psmprocs:\n",
    "    psmproc = psm.procsum_time_clock/delt\n",
    "    plt.step(x=psm_tfix, y=psmproc, where='pre', color='cyan', label=f\"Procsum processes [{len(psmproc)}] {psmproc.median():.1f}\")\n",
    "# Task count\n",
    "plt.plot(tscrun.tfix, tscact, '.', color='orchid', label=f\"Task processes [{len(tscact)}] {tscact.median():.1f}\")\n",
    "# Task utilization count\n",
    "if have_procsum:\n",
    "    # To get a process estimate, we divide the total user+sys time by the time interval and number of CPU.\n",
    "    puse = (psm.procsum_time_user+psm.procsum_time_system)/delt\n",
    "    plt.step(x=psm_tfix, y=puse, where='pre', color='forestgreen', marker='', linestyle='-', label=f\"Task utilization [{len(puse)}] med={puse.median():0.1f}\")\n",
    "    print(f\"Utilization count: {len(puse)}\")\n",
    "plt.xlabel(f\"Time [{stunit}]\")\n",
    "plt.ylabel('Cumlative CPU count')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "junk = plt.axis([xmin, xmax, ymin, ymax])\n",
    "plt.title(pttl)\n",
    "plt.savefig(pfx+'cpucount'+sfx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5371dfbc-9b3c-48f7-aeb4-17d8f027c1fa",
   "metadata": {},
   "source": [
    "## System state counts\n",
    "\n",
    "The following shows, as a function time, the cumlative number of CPUs in the user, system, iowait and idle states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9387209e-e91d-49fd-bede-fdeaae5988f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sumtime(a, t):\n",
    "    sum = 0.0\n",
    "    na = len(a)\n",
    "    for i in range(1, na):\n",
    "        sum += a[i]*(t[i]-t[i-1])\n",
    "    return sum\n",
    "\n",
    "if havesym:\n",
    "    xmin = tmin\n",
    "    xmax = tmax\n",
    "    ymin = 0\n",
    "    fac = ncpu\n",
    "    ymax = taskrunmax\n",
    "    cpt = sym.tfix \n",
    "    cpusr = fac*sym.cpu_user/sym.cpu_time\n",
    "    cpsys = fac*sym.cpu_system/sym.cpu_time\n",
    "    cpiow = fac*sym.cpu_iowait/sym.cpu_time\n",
    "    cpidl = fac*sym.cpu_idle/sym.cpu_time\n",
    "    scptfac = \"hour\"\n",
    "    cptfac = tunit/3600  # Convert to {scptfac}\n",
    "    smusr = cptfac*sumtime(cpusr, cpt)\n",
    "    smsys = cptfac*sumtime(cpsys, cpt)\n",
    "    smiow = cptfac*sumtime(cpiow, cpt)\n",
    "    smidl = cptfac*sumtime(cpidl, cpt)\n",
    "    csmusr = smusr\n",
    "    csmsys = csmusr + smsys\n",
    "    csmiow = csmsys + smiow\n",
    "    csmidl = csmiow + smidl\n",
    "    plt.figure(figsize=(pdx, pdy))\n",
    "    plt.step(x=cpt, y=cpusr+cpsys+cpiow+cpidl, color='black', label=f\"+ Idle $\\eta$={cpidl.median():.1f} $\\Sigma$={csmidl:.2f} {scptfac}\") \n",
    "    plt.step(x=cpt, y=cpusr+cpsys+cpiow, color='red', label=f\"+ IOwait $\\eta$={cpiow.median():.1f} $\\Sigma$={csmiow:.2f} {scptfac}\")\n",
    "    plt.step(x=cpt, y=cpusr+cpsys, color='green', label=f\"+ System $\\eta$={cpsys.median():.1f} $\\Sigma$={csmsys:.2f} {scptfac}\")\n",
    "    plt.step(x=cpt, y=cpusr, color='blue', label=f\"User [{len(cpusr)}] $\\eta$={cpusr.median():.1f} $\\Sigma$={csmusr:.2f} {scptfac}\")\n",
    "    plt.plot(tscrun.tfix, tscact, ',', color='gray', label=f\"Number of running tasks $\\eta$={tscact.median():.1f}\")\n",
    "    plt.xlabel(f\"Time [{stunit}]\")\n",
    "    plt.ylabel('CPU state count')\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='right')\n",
    "    junk = plt.axis([xmin, xmax, ymin, ymax])\n",
    "    plt.title(pttl)\n",
    "    plt.savefig(pfx+'cpu-state-count'+sfx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c974e2-d323-4bfe-bb0b-b7944998ade1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Memory usage\n",
    "\n",
    "The following plot shows the total memory used by the system and that used by running tasks.\n",
    "The former is obtained from the system monitor and the latter from procsum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0122ee12-6f11-4711-9205-901efdb98a5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xmin = tmin\n",
    "xmax = tmax\n",
    "ymin = 0\n",
    "ymax = 1.02*maxmem\n",
    "\n",
    "plt.figure(figsize=(pdx, pdy))\n",
    "\n",
    "if have_procsum:\n",
    "    xdat2 = psm_tfix\n",
    "    ydat2 = 1.e-12*psm.procsum_memory_virtual*maxmem\n",
    "    lab2 = f\"Task vmem sum [{len(ydat2)}] {ydat2.median():.1f} GB\"\n",
    "    plt.step(xdat2, ydat2, color='blue', label=lab2)\n",
    "    ydat3 = 1.e-9*psm.procsum_memory_resident\n",
    "    lab3 = f\"Task RSS sum [{len(ydat3)}] {ydat3.median():.1f} GB\"\n",
    "    plt.step(xdat2, ydat3, color='teal', label=lab3)\n",
    "    \n",
    "xdat = sym.tfix\n",
    "ydat = sym.mem_total - sym.mem_available\n",
    "plt.step(xdat, ydat, color='orange', label=f\"System [{len(ydat)}] max: {ydat.max():.1f} GB\")\n",
    "\n",
    "plt.xlabel(f\"Time [{stunit}]\")\n",
    "plt.ylabel('Memory [GB]')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "junk = plt.axis([xmin, xmax, ymin, ymax])\n",
    "plt.title(pttl)\n",
    "plt.savefig(pfx+'memory'+sfx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567f6bd4-039c-4779-85b4-6f8674fb6abc",
   "metadata": {},
   "source": [
    "## I/O rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a49f7e-4d03-44af-a8a5-7b00e3a991f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "have_ioplot = have_procsum or have_taskout\n",
    "if have_ioplot:\n",
    "    plt.figure(figsize=(pdx, pdy))\n",
    "if have_procsum:\n",
    "    rea = psm.procsum_disk_read/gb/delt\n",
    "    wri = psm.procsum_disk_write/gb/delt\n",
    "    plt.plot(psm.tfix, rea, 'b+', label=f\"Input [{len(rea)}] {rea.median():.2f} GB/s\")\n",
    "    plt.plot(psm.tfix, wri, 'rx', label=f\"Output [{len(wri)}] {wri.median():0.2f} GB/s\")\n",
    "if have_taskout:\n",
    "    x = df_taskout.tfix\n",
    "    y = df_taskout.rate\n",
    "    plt.plot(x, y, '1r', label=f\"Task output [{len(y)}] {y.median():.2f} GB/s\")\n",
    "if have_ioplot:\n",
    "    plt.xlabel(f\"Time [{stunit}]\")\n",
    "    plt.ylabel('Disk I/O [GB/s]')\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    junk = plt.axis([tmin, tmax, 0, 4])\n",
    "    plt.title(pttl)\n",
    "    plt.savefig(pfx+'io'+sfx)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd18176-e0ce-41a5-ba0a-d3c6fa0e1213",
   "metadata": {},
   "outputs": [],
   "source": [
    "if have_ioplot:\n",
    "    xmin = tmin\n",
    "    xmax = tmax\n",
    "    ymin = 0.0\n",
    "    ymax = monexp.iosummax\n",
    "    plt.figure(figsize=(pdx, pdy))\n",
    "if have_procsum:\n",
    "    readgb = psm.procsum_disk_read.cumsum()/gb\n",
    "    writgb = psm.procsum_disk_write.cumsum()/gb\n",
    "    print(f\" Read sum: {readgb.max():8.1f} GB\")\n",
    "    print(f\"Write sum: {writgb.max():8.1f} GB\")\n",
    "    plt.plot(psm.tfix, readgb, 'b+', label='Input')\n",
    "    plt.plot(psm.tfix, psm.procsum_disk_write.cumsum()/gb, 'rx', label='Output')\n",
    "if have_taskout:\n",
    "    x = df_taskout.tfix\n",
    "    y = df_taskout['size']\n",
    "    plt.plot(x, y, 'r1', label=f\"Task output [{len(y)}] {y.max():.2f} GB\")\n",
    "if have_ioplot:\n",
    "    plt.xlabel(f\"Time [{stunit}]\")\n",
    "    plt.ylabel('Disk I/O [GB]')\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    junk = plt.axis([xmin, xmax, ymin, ymax])\n",
    "    #print(junk)\n",
    "    plt.title(pttl)\n",
    "    plt.savefig(pfx+'io2'+sfx)\n",
    "    plt.show()\n",
    "    #print(plt.rcParams)\n",
    "    #print(psm.tfix, psm.procsum_disk_write.cumsum()/gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0623114a-e421-43fc-9293-39a217d6445a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Latency\n",
    "Task submission latency is evaluated by assigning tasks to chains and defining the latency as the time between the end of one task and start of the next in a chain.\n",
    "This latency estimate is suspect if the executor runs a variable number of workers.\n",
    "For a fixed value, there is one chain per worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ba8eff-e78b-4ab1-9c12-b3e14f1c8f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbr.chaintasks()\n",
    "print(f\"  Total chain count: {dbr.taskchain_count('all')}\")\n",
    "print(f\"   Late chain count: {dbr.taskchain_count('late')}\")\n",
    "print(f\"       Mean latency: {tst.latency.mean():.2f} sec\")\n",
    "task_id_plot = monexp.task_id_plot\n",
    "if isinstance(task_id_plot, int):\n",
    "    task_idx_plot = task_id_plot\n",
    "elif task_id_plot is not None:\n",
    "    task_idx_plot = dbr.taskIndexFromName[task_id_plot]\n",
    "if dbr.taskchain_count():\n",
    "    xmin = tmin\n",
    "    xmax = tmax\n",
    "    ymin = 0\n",
    "    ymax = monexp.tlatencymax\n",
    "    if task_id_plot is None:\n",
    "        ttst = tst\n",
    "        tpttl = pttl\n",
    "    else:\n",
    "        print(f\"Plotting only for task {task_id_plot}\")\n",
    "        ttst = tst.query(f\"task_idx=={task_idx_plot}\")\n",
    "        tpttl = pttl + f\" Task {task_id_plot}\"\n",
    "    tsklat = ttst.latency.clip(0,0.995*ymax)\n",
    "    lablat = f\"Latency [{len(tsklat)}] {ttst.latency.mean():.1f} sec\"\n",
    "    collat = 'indianred'\n",
    "    plt.figure(figsize=(pdx, pdy))\n",
    "    plt.plot(ttst.tfix_running, tsklat, color=collat, marker='+', linestyle='none', label=lablat)\n",
    "    plt.xlabel(f\"Time [{stunit}]\")\n",
    "    plt.ylabel('Task try latency [sec]')\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    junk = plt.axis([xmin, xmax, ymin, ymax])\n",
    "    plt.title(pttl)\n",
    "    plt.savefig(pfx+'latency_vs_time'+sfx)\n",
    "    plt.show()\n",
    "    # Latency and run time\n",
    "    ymin = 0\n",
    "    ymax = monexp.tlatrunmax\n",
    "    tsklat = ttst.latency.clip(0,0.995*ymax)\n",
    "    tskrun = ttst['trun'].clip(0,0.995*ymax)\n",
    "    tskpst = ttst['tpst'].clip(0, 0.995*ymax)\n",
    "    labrun = f\"Run time [{len(tsklat)}] {tskrun.mean():.1f} sec\"\n",
    "    labpst = f\"Post-processing time [{len(tskpst)}] {tskpst.mean():.1f} sec\"\n",
    "    colrun = 'slateblue'\n",
    "    colpst = 'orange'\n",
    "    tsksum = (ttst.latency+ttst.trun+ttst.tpst).clip(0,0.995*ymax)\n",
    "    labsum = f\"Sum [{len(tsksum)}] {tsksum.mean():.1f} sec\"\n",
    "    colsum = 'gray'\n",
    "    plt.figure(figsize=(pdx, pdy))\n",
    "    mrk = '+'\n",
    "    plt.plot(ttst.tfix_running, tsksum, color=colsum, marker='x', linestyle='none', label=labsum)\n",
    "    plt.plot(ttst.tfix_running, tskrun, color=colrun,  marker=mrk, linestyle='none', label=labrun)\n",
    "    plt.plot(ttst.tfix_running, tskpst, color=colpst,  marker=mrk, linestyle='none', label=labpst)\n",
    "    plt.plot(ttst.tfix_running, tsklat, color=collat, marker=mrk, linestyle='none', label=lablat)\n",
    "    plt.xlabel(f\"Time [{stunit}]\")\n",
    "    plt.ylabel('Task time [sec]')\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    junk = plt.axis([xmin, xmax, ymin, ymax])\n",
    "    plt.title(tpttl)\n",
    "    plt.savefig(pfx+'latrun_vs_time'+sfx)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc3cfe7-3985-4ffd-8e13-5cf44aa11356",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
